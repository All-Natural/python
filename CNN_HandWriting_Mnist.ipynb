{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_HandWriting_Mnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/All-Natural/python/blob/master/CNN_HandWriting_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0DX2BAhXrGr",
        "outputId": "afaf40c7-4a09-4a32-84dc-31dba54ef8ed"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 100\n",
        "num_classes = 10\n",
        "epochs = 80\n",
        "\n",
        "# input image dimensions\n",
        "# https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000,28,28,1)\n",
        "x_test = x_test.reshape(10000,28,28,1)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"=================\")\n",
        "print(\"Train loss:\", score[0])\n",
        "print(\"Train accuracy:\", score[1])\n",
        "print(\"=================\")\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"=================\")\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "print(\"=================\")\n",
        "model.predict(x_test)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/80\n",
            "600/600 [==============================] - 11s 7ms/step - loss: 26.9655 - accuracy: 0.1301 - val_loss: 3.3407 - val_accuracy: 0.4558\n",
            "Epoch 2/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 10.6601 - accuracy: 0.2562 - val_loss: 1.5053 - val_accuracy: 0.5946\n",
            "Epoch 3/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 5.2905 - accuracy: 0.3338 - val_loss: 1.2787 - val_accuracy: 0.5800\n",
            "Epoch 4/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 3.2226 - accuracy: 0.3563 - val_loss: 1.4422 - val_accuracy: 0.5302\n",
            "Epoch 5/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 2.4137 - accuracy: 0.3631 - val_loss: 1.5252 - val_accuracy: 0.5561\n",
            "Epoch 6/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 2.1305 - accuracy: 0.3763 - val_loss: 1.5234 - val_accuracy: 0.5698\n",
            "Epoch 7/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.9751 - accuracy: 0.4009 - val_loss: 1.4509 - val_accuracy: 0.5984\n",
            "Epoch 8/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.8853 - accuracy: 0.4260 - val_loss: 1.3813 - val_accuracy: 0.6277\n",
            "Epoch 9/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.7870 - accuracy: 0.4418 - val_loss: 1.3123 - val_accuracy: 0.6559\n",
            "Epoch 10/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.7144 - accuracy: 0.4649 - val_loss: 1.2233 - val_accuracy: 0.6879\n",
            "Epoch 11/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.6597 - accuracy: 0.4836 - val_loss: 1.1460 - val_accuracy: 0.7087\n",
            "Epoch 12/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.6084 - accuracy: 0.5078 - val_loss: 1.0873 - val_accuracy: 0.7293\n",
            "Epoch 13/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.5478 - accuracy: 0.5277 - val_loss: 1.0309 - val_accuracy: 0.7444\n",
            "Epoch 14/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.4973 - accuracy: 0.5416 - val_loss: 0.9715 - val_accuracy: 0.7598\n",
            "Epoch 15/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.4695 - accuracy: 0.5507 - val_loss: 0.9217 - val_accuracy: 0.7753\n",
            "Epoch 16/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.4044 - accuracy: 0.5667 - val_loss: 0.8747 - val_accuracy: 0.7882\n",
            "Epoch 17/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.3671 - accuracy: 0.5830 - val_loss: 0.8338 - val_accuracy: 0.7995\n",
            "Epoch 18/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.3405 - accuracy: 0.5955 - val_loss: 0.8071 - val_accuracy: 0.8083\n",
            "Epoch 19/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.3208 - accuracy: 0.5994 - val_loss: 0.7751 - val_accuracy: 0.8169\n",
            "Epoch 20/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.2722 - accuracy: 0.6170 - val_loss: 0.7437 - val_accuracy: 0.8248\n",
            "Epoch 21/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.2586 - accuracy: 0.6213 - val_loss: 0.7157 - val_accuracy: 0.8306\n",
            "Epoch 22/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.2319 - accuracy: 0.6336 - val_loss: 0.6929 - val_accuracy: 0.8351\n",
            "Epoch 23/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.1982 - accuracy: 0.6428 - val_loss: 0.6666 - val_accuracy: 0.8415\n",
            "Epoch 24/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.1700 - accuracy: 0.6523 - val_loss: 0.6407 - val_accuracy: 0.8476\n",
            "Epoch 25/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.1581 - accuracy: 0.6539 - val_loss: 0.6191 - val_accuracy: 0.8508\n",
            "Epoch 26/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.1222 - accuracy: 0.6636 - val_loss: 0.5977 - val_accuracy: 0.8573\n",
            "Epoch 27/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.1064 - accuracy: 0.6709 - val_loss: 0.5788 - val_accuracy: 0.8598\n",
            "Epoch 28/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.1042 - accuracy: 0.6732 - val_loss: 0.5649 - val_accuracy: 0.8646\n",
            "Epoch 29/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.0680 - accuracy: 0.6776 - val_loss: 0.5462 - val_accuracy: 0.8680\n",
            "Epoch 30/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.0531 - accuracy: 0.6896 - val_loss: 0.5305 - val_accuracy: 0.8704\n",
            "Epoch 31/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 1.0268 - accuracy: 0.6930 - val_loss: 0.5154 - val_accuracy: 0.8741\n",
            "Epoch 32/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.9990 - accuracy: 0.7018 - val_loss: 0.5044 - val_accuracy: 0.8760\n",
            "Epoch 33/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.9863 - accuracy: 0.7085 - val_loss: 0.4901 - val_accuracy: 0.8787\n",
            "Epoch 34/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.9750 - accuracy: 0.7106 - val_loss: 0.4775 - val_accuracy: 0.8815\n",
            "Epoch 35/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.9506 - accuracy: 0.7163 - val_loss: 0.4633 - val_accuracy: 0.8846\n",
            "Epoch 36/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.9310 - accuracy: 0.7223 - val_loss: 0.4554 - val_accuracy: 0.8861\n",
            "Epoch 37/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.9305 - accuracy: 0.7225 - val_loss: 0.4447 - val_accuracy: 0.8880\n",
            "Epoch 38/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.9058 - accuracy: 0.7309 - val_loss: 0.4375 - val_accuracy: 0.8898\n",
            "Epoch 39/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.8914 - accuracy: 0.7319 - val_loss: 0.4282 - val_accuracy: 0.8913\n",
            "Epoch 40/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.8969 - accuracy: 0.7344 - val_loss: 0.4161 - val_accuracy: 0.8933\n",
            "Epoch 41/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.8758 - accuracy: 0.7390 - val_loss: 0.4074 - val_accuracy: 0.8963\n",
            "Epoch 42/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.8593 - accuracy: 0.7441 - val_loss: 0.4015 - val_accuracy: 0.8993\n",
            "Epoch 43/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.8533 - accuracy: 0.7443 - val_loss: 0.3951 - val_accuracy: 0.9022\n",
            "Epoch 44/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.8600 - accuracy: 0.7472 - val_loss: 0.3886 - val_accuracy: 0.9045\n",
            "Epoch 45/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.8290 - accuracy: 0.7539 - val_loss: 0.3793 - val_accuracy: 0.9056\n",
            "Epoch 46/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.8055 - accuracy: 0.7617 - val_loss: 0.3697 - val_accuracy: 0.9082\n",
            "Epoch 47/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.8050 - accuracy: 0.7590 - val_loss: 0.3638 - val_accuracy: 0.9083\n",
            "Epoch 48/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7913 - accuracy: 0.7627 - val_loss: 0.3568 - val_accuracy: 0.9115\n",
            "Epoch 49/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7793 - accuracy: 0.7655 - val_loss: 0.3506 - val_accuracy: 0.9144\n",
            "Epoch 50/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7839 - accuracy: 0.7669 - val_loss: 0.3455 - val_accuracy: 0.9156\n",
            "Epoch 51/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7660 - accuracy: 0.7716 - val_loss: 0.3365 - val_accuracy: 0.9175\n",
            "Epoch 52/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7529 - accuracy: 0.7757 - val_loss: 0.3312 - val_accuracy: 0.9178\n",
            "Epoch 53/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7464 - accuracy: 0.7770 - val_loss: 0.3246 - val_accuracy: 0.9201\n",
            "Epoch 54/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7325 - accuracy: 0.7815 - val_loss: 0.3194 - val_accuracy: 0.9216\n",
            "Epoch 55/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7203 - accuracy: 0.7843 - val_loss: 0.3152 - val_accuracy: 0.9231\n",
            "Epoch 56/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7298 - accuracy: 0.7848 - val_loss: 0.3122 - val_accuracy: 0.9233\n",
            "Epoch 57/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.7090 - accuracy: 0.7909 - val_loss: 0.3065 - val_accuracy: 0.9239\n",
            "Epoch 58/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6949 - accuracy: 0.7926 - val_loss: 0.3003 - val_accuracy: 0.9254\n",
            "Epoch 59/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6923 - accuracy: 0.7924 - val_loss: 0.2968 - val_accuracy: 0.9265\n",
            "Epoch 60/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6857 - accuracy: 0.7943 - val_loss: 0.2912 - val_accuracy: 0.9278\n",
            "Epoch 61/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6909 - accuracy: 0.7955 - val_loss: 0.2868 - val_accuracy: 0.9286\n",
            "Epoch 62/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6749 - accuracy: 0.7984 - val_loss: 0.2811 - val_accuracy: 0.9301\n",
            "Epoch 63/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6577 - accuracy: 0.8027 - val_loss: 0.2781 - val_accuracy: 0.9300\n",
            "Epoch 64/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6551 - accuracy: 0.8041 - val_loss: 0.2743 - val_accuracy: 0.9312\n",
            "Epoch 65/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6348 - accuracy: 0.8087 - val_loss: 0.2688 - val_accuracy: 0.9314\n",
            "Epoch 66/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6351 - accuracy: 0.8083 - val_loss: 0.2649 - val_accuracy: 0.9323\n",
            "Epoch 67/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6432 - accuracy: 0.8085 - val_loss: 0.2624 - val_accuracy: 0.9327\n",
            "Epoch 68/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6236 - accuracy: 0.8144 - val_loss: 0.2594 - val_accuracy: 0.9333\n",
            "Epoch 69/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6209 - accuracy: 0.8148 - val_loss: 0.2571 - val_accuracy: 0.9336\n",
            "Epoch 70/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6085 - accuracy: 0.8191 - val_loss: 0.2512 - val_accuracy: 0.9346\n",
            "Epoch 71/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6097 - accuracy: 0.8172 - val_loss: 0.2481 - val_accuracy: 0.9347\n",
            "Epoch 72/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.5931 - accuracy: 0.8210 - val_loss: 0.2449 - val_accuracy: 0.9360\n",
            "Epoch 73/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.5885 - accuracy: 0.8249 - val_loss: 0.2427 - val_accuracy: 0.9363\n",
            "Epoch 74/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6151 - accuracy: 0.8205 - val_loss: 0.2403 - val_accuracy: 0.9364\n",
            "Epoch 75/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.5943 - accuracy: 0.8232 - val_loss: 0.2368 - val_accuracy: 0.9382\n",
            "Epoch 76/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.5717 - accuracy: 0.8321 - val_loss: 0.2343 - val_accuracy: 0.9382\n",
            "Epoch 77/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.5677 - accuracy: 0.8296 - val_loss: 0.2319 - val_accuracy: 0.9396\n",
            "Epoch 78/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.5803 - accuracy: 0.8251 - val_loss: 0.2293 - val_accuracy: 0.9403\n",
            "Epoch 79/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.5725 - accuracy: 0.8290 - val_loss: 0.2258 - val_accuracy: 0.9405\n",
            "Epoch 80/80\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.5576 - accuracy: 0.8369 - val_loss: 0.2218 - val_accuracy: 0.9421\n",
            "=================\n",
            "Train loss: 0.22706590592861176\n",
            "Train accuracy: 0.9394999742507935\n",
            "=================\n",
            "=================\n",
            "Test loss: 0.22176344692707062\n",
            "Test accuracy: 0.9420999884605408\n",
            "=================\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}